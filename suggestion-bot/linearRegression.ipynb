{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d6f6313c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plugging Libraries\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f4c690e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading Data\n",
    "df_train = pd.read_csv('therapy_train.csv')\n",
    "df_test = pd.read_csv('therapy_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8e3ea30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8000 entries, 0 to 7999\n",
      "Data columns (total 9 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   emotional_state  8000 non-null   int64 \n",
      " 1   duration         8000 non-null   int64 \n",
      " 2   concern_type     8000 non-null   int64 \n",
      " 3   urgency          8000 non-null   int64 \n",
      " 4   support_style    8000 non-null   int64 \n",
      " 5   tech_openness    8000 non-null   int64 \n",
      " 6   availability     8000 non-null   int64 \n",
      " 7   clarity          8000 non-null   int64 \n",
      " 8   label            8000 non-null   object\n",
      "dtypes: int64(8), object(1)\n",
      "memory usage: 562.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "98bc7684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "7995    0\n",
      "7996    0\n",
      "7997    0\n",
      "7998    1\n",
      "7999    1\n",
      "Name: label, Length: 8000, dtype: int64\n",
      "0       1\n",
      "1       1\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "1995    0\n",
      "1996    1\n",
      "1997    1\n",
      "1998    0\n",
      "1999    1\n",
      "Name: label, Length: 2000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_train['label'] = df_train['label'].map({'Human':0,'Hybrid':1,'AI':2})\n",
    "df_test['label'] = df_test['label'].map({'Human':0,'Hybrid':1,'AI':2})\n",
    "\n",
    "print(df_train['label'])\n",
    "print(df_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4f44f276",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Splitting Data\n",
    "X = df_train.drop(columns=['label'])\n",
    "y = df_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "41ce957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train_Test_Split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5e7fd3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Recall: 1.0\n",
      "Precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "## Model building\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train,y_train)\n",
    "preds = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test,preds))\n",
    "print(\"Recall:\", recall_score(y_test,preds, average='weighted'))\n",
    "print(\"Precision:\", precision_score(y_test,preds, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a58f6899",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_dropped = df_test.drop(columns=['label'])\n",
    "test_pred = model.predict(df_test_dropped)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'ml_pred': test_pred,\n",
    "    'actual': df_test['label']\n",
    "})\n",
    "\n",
    "submission.to_csv('check.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dbd6b51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matching rows: 2000\n"
     ]
    }
   ],
   "source": [
    "check = pd.read_csv('check.csv')\n",
    "\n",
    "check_ml = check['ml_pred']\n",
    "check_actual = check['actual']\n",
    "\n",
    "matches = (check_ml == check_actual).sum()\n",
    "\n",
    "print(f\"Number of matching rows: {matches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "91a58e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new_model.pkl']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, 'new_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
